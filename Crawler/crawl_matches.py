# crawl_matches.py
import requests
import time
from config import FOOTBALL_API_URL, FOOTBALL_HEADERS, COMPETITIONS_ID
from database import save_match_to_db


def fetch_finished_matches(comp_id):
    """
    L·∫•y l·ªãch s·ª≠ ƒë·∫•u c·ªßa m·ªôt gi·∫£i c·ª• th·ªÉ
    """
    # Endpoint: /competitions/{id}/matches?status=FINISHED
    # API Free gi·ªõi h·∫°n request, n√™n ch·ªâ l·∫•y m√πa hi·ªán t·∫°i m·∫∑c ƒë·ªãnh
    url = f"{FOOTBALL_API_URL}/competitions/{comp_id}/matches"

    params = {
        "status": "FINISHED"  # Ch·ªâ l·∫•y tr·∫≠n ƒë√£ ƒë√° xong
        # "dateFrom": "2024-01-01", # C√≥ th·ªÉ l·ªçc theo ng√†y n·∫øu mu·ªën
        # "dateTo": "2024-01-31"
    }

    try:
        print(f"--- ƒêang t·∫£i d·ªØ li·ªáu gi·∫£i ID: {comp_id} ---")
        res = requests.get(url, headers=FOOTBALL_HEADERS, params=params)

        if res.status_code == 200:
            data = res.json()
            matches = data.get("matches", [])
            print(f"‚úÖ T√¨m th·∫•y {len(matches)} tr·∫≠n ƒë·∫•u ƒë√£ k·∫øt th√∫c.")

            for match in matches:
                save_match_to_db(match)
        else:
            print(f"‚ö†Ô∏è L·ªói API ({res.status_code}): {res.text}")

    except Exception as e:
        print(f"‚ùå L·ªói connection: {e}")


if __name__ == "__main__":
    # Duy·ªát qua danh s√°ch gi·∫£i ƒë·∫•u trong config
    for comp_id, comp_name in COMPETITIONS_ID.items():
        print(f"üèÜ B·∫Øt ƒë·∫ßu c√†o: {comp_name}")
        fetch_finished_matches(comp_id)

        # QUAN TR·ªåNG: API Free ch·ªâ cho 10 request/ph√∫t.
        # M·ªói l·∫ßn g·ªçi request xong ngh·ªâ 7 gi√¢y ƒë·ªÉ an to√†n (60s / 10req = 6s)
        print("‚è≥ Ngh·ªâ 7 gi√¢y ƒë·ªÉ tr√°nh kh√≥a API...")
        time.sleep(7)